{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from openpyxl.utils import get_column_letter\n",
    "from pandas import ExcelWriter\n",
    "import numpy as np\n",
    "import pyperclip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读取与预处理\n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    读取xlsx并预处理数据\n",
    "    \"\"\"\n",
    "    def convert_uid(x:str):\n",
    "        return x.strip(\"用户ID \")\n",
    "\n",
    "    def convert_date(x:str):\n",
    "        return datetime.strptime(x,\"%y-%m-%d %H:%M\")\n",
    "\n",
    "    def get_tid(x:str):\n",
    "        if m:=re.search(r'tid=(\\d+)',x):\n",
    "            return m.group(1)\n",
    "        else:\n",
    "            return \"-1\"\n",
    "\n",
    "    data = pd.read_excel(io=filepath,usecols='C:K',converters={'uid':convert_uid,'publish_time':convert_date,'reply_time':convert_date})\n",
    "\n",
    "    # 补全用户名\n",
    "    for index, row in data.iterrows():\n",
    "        if not pd.isnull(row['publisher_fullname']):\n",
    "            row['publisher'] = row['publisher_fullname']\n",
    "        data.iloc[index] = row\n",
    "    data.drop('publisher_fullname',axis =1,inplace=True)\n",
    "\n",
    "    # 提取tid\n",
    "    data['tid'] = data['link'].map(get_tid)\n",
    "    \n",
    "    # 删除link列（因为可以通过tid得到，就不需要这种冗余数据了）\n",
    "    data.drop('link',axis=1,inplace=True)\n",
    "    \n",
    "    # 将楼层为空的行填充\n",
    "    # 将空分区填充为空字符串\n",
    "    data.fillna({'level':0,'area':''},inplace=True)\n",
    "    \n",
    "    # 将楼层列转化为整数\n",
    "    data['level'] = data['level'].astype('int64')\n",
    "    \n",
    "    # 匿名用户的uid改为-1\n",
    "    data.loc[data['uid'].str.startswith(\"#anony\"),'uid'] = -1\n",
    "    \n",
    "    # 调整列顺序\n",
    "    data = data[['tid','level','title','uid','publisher','publish_time','reply_time','area']]\n",
    "\n",
    "\n",
    "    # 将tid设置为索引\n",
    "    data.set_index('tid',inplace=True,drop=False)\n",
    "    return data\n",
    "\n",
    "# 没做交互，手动改时间\n",
    "datetime_last = datetime(2023,7,2,19,32) # 上周采集数据的时间\n",
    "datetime_this = datetime(2023,7,9,21,41) # 本周采集数据的时间\n",
    "file_time_format = \"%Y-%m-%d-%H%M\" # 本地文件名的时间格式，目前是nga-thread-2023-02-05-1208.xlsx这种格式\n",
    "\n",
    "data_last = load_data(f'raw_data/nga-thread-{datetime_last.strftime(file_time_format)}.xlsx')\n",
    "data_this = load_data(f'raw_data/nga-thread-{datetime_this.strftime(file_time_format)}.xlsx')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存预处理数据\n",
    "\n",
    "def to_excel_auto_column_weight(df: pd.DataFrame, writer: ExcelWriter, sheet_name):\n",
    "    \"\"\"\n",
    "    DataFrame保存为excel并自动设置列宽\n",
    "    代码来源：https://laowangblog.com/pandas-openpyxl-excel-column-dimensions.html\n",
    "    \"\"\"\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    #  计算表头的字符宽度\n",
    "    column_widths = (\n",
    "        df.columns.to_series().apply(lambda x: len(x)).values\n",
    "    )\n",
    "    #  计算每列的最大字符宽度\n",
    "    max_widths = (\n",
    "        df.astype(str).applymap(lambda x: len(x)).agg(max).values\n",
    "    )\n",
    "    # 计算整体最大宽度\n",
    "    widths = np.max([column_widths, max_widths], axis=0)\n",
    "    # 设置列宽\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    for i, width in enumerate(widths, 1):\n",
    "        # openpyxl引擎设置字符宽度时会缩水0.5左右个字符，所以干脆+2使左右都空出一个字宽。\n",
    "        worksheet.column_dimensions[get_column_letter(i)].width = width + 2\n",
    "\n",
    "with pd.ExcelWriter(f'data/data-{datetime_last.strftime(file_time_format)}.xlsx', engine='openpyxl') as writer:\n",
    "    to_excel_auto_column_weight(data_last, writer, f'data')\n",
    "\n",
    "with pd.ExcelWriter(f'data/data-{datetime_this.strftime(file_time_format)}.xlsx', engine='openpyxl') as writer:\n",
    "    to_excel_auto_column_weight(data_this, writer, f'data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过滤非单人安科帖和交流帖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤非单人安科帖\n",
    "def filter_anko_threads(data:pd.DataFrame):\n",
    "    # 去除地下城分区的帖子\n",
    "    data = data[data['area'] != \"[地下城(多人安科/TRPG区)]\"]\n",
    "    # 去除图书馆分区的帖子\n",
    "    data = data[data['area'] != \"[图书馆(资料交流区)]\"]\n",
    "    # 筛选含有安科标签的帖子\n",
    "    data = data[data['title'].str.contains('\\[安科\\]') | data['title'].str.contains('\\[安价\\]') | data['title'].str.contains('\\[安科/安价\\]') | data['title'].str.contains('\\[安价/安科\\]')]\n",
    "    return data\n",
    "\n",
    "data_last = filter_anko_threads(data_last)\n",
    "data_this = filter_anko_threads(data_this)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 筛选出本周达到x楼的安科的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diff(df1:pd.DataFrame,df2:pd.DataFrame):\n",
    "    '''\n",
    "    求差集，返回 df1 - df2\n",
    "    '''\n",
    "    return pd.concat([df1,df2,df2]).drop_duplicates(subset=['tid'],keep=False)\n",
    "\n",
    "# 筛选出本周达到x楼的安科的数据\n",
    "def filter_arrive_x_level(last_source:pd.DataFrame,this_source:pd.DataFrame,x:int):\n",
    "    \"\"\"\n",
    "    筛选出本周达到x楼的安科的数据\n",
    "    \"\"\"\n",
    "    # 已经达到x楼\n",
    "    this_dist = this_source[(this_source['level'] >= x)]\n",
    "    last_dist = last_source[(last_source['level'] >= x)]\n",
    "\n",
    "    # 去除上次已经达到的，即两者差集，this_dist - last_dist\n",
    "    # result = pd.concat([this_dist,last_dist,last_dist]).drop_duplicates(subset=['tid'],keep=False)\n",
    "    result = diff(this_dist,last_dist)\n",
    "    \n",
    "    # 如果得到的tid不存在于上次的表中(可能是新发布或是上次采集数据时进入审核，后者需要去掉)，则去除\n",
    "    # 即，筛选result中tid存在于上次的表中的行，或者发布时间在两次的表的收集时间之间的行\n",
    "    result = result[(result['tid'].isin(last_source['tid'])) | ((datetime_last < result['publish_time']) & (result['publish_time'] < datetime_this))]\n",
    "    \n",
    "    # 按照楼层升序\n",
    "    result = result.sort_values(by='level',ascending=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# 数据统计\n",
    "\n",
    "# 本周新增安科\n",
    "new_threads = data_this[(datetime_last <= data_this['publish_time']) & (data_this['publish_time'] <= datetime_this)]\n",
    "new_threads.fillna(0)\n",
    "\n",
    "# 小于x层的安科数\n",
    "def num_lower_than_x(x:int):\n",
    "    return len(data_this[data_this['level'] < x])\n",
    "\n",
    "# 总数\n",
    "thread_sum = len(data_this)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本周完结的安科"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本周完结的安科\n",
    "def filter_finished_threads(last_source:pd.DataFrame,this_source:pd.DataFrame):\n",
    "    last_dist = last_source[last_source['area'] == \"[记忆回廊(完结区)]\"]\n",
    "    this_dist = this_source[this_source['area'] == \"[记忆回廊(完结区)]\"]\n",
    "    \n",
    "    # 去除上次已经达到的，即两者差集，this_dist - last_dist\n",
    "    result = diff(this_dist,last_dist)\n",
    "    \n",
    "    # 如果得到的tid不存在于上次的表中，则去除\n",
    "    # 即，筛选result中tid存在于上次的表中的行\n",
    "    result = result[result['tid'].isin(last_source['tid'])]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "finished_threads = filter_finished_threads(data_last,data_this)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本周活跃数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_data = data_this['level'] - data_last['level']\n",
    "\n",
    "active_data = active_data[active_data.notna() & active_data != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取复更安科\n",
    "def get_revive_threads(data:pd.DataFrame):\n",
    "    return data[data['title'].str.contains('\\[恢复更新\\]') & ((datetime_this- data['reply_time']) <= pd.Timedelta(days=30))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出排版文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# url = f\"https://ngabbs.com/read.php?tid={data_this['tid'][0]}&__output=11\"\n",
    "# url = \"https://ngabbs.com/read.php?tid=36054869&__output=11\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36\",\n",
    "    \"Cookie\":\"\"\n",
    "}\n",
    "\n",
    "def get_brief(tid:str,size:int):\n",
    "    response = requests.get(f\"https://ngabbs.com/read.php?tid={tid}&__output=11\",headers=headers)\n",
    "    print(response.status_code)  # 获取响应状态码\n",
    "    print(response.headers)  # 获取响应头\n",
    "    print(response.content)  # 获取响应内容\n",
    "\n",
    "    json_data = response.json()\n",
    "    \n",
    "    content = json_data['data']['__R'][0]['content']\n",
    "    content = re.sub(r\"(\\[.*?\\])\",\"\",content)#删除所有中括号代码\n",
    "    content = re.sub(r\"<br/>\",\"\",content)#删除所有中括号代码\n",
    "    \n",
    "    return content[0:size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出排版文本\n",
    "\n",
    "def data_to_bbcode(data:pd.DataFrame,col_name='level',show_reply_time=False):\n",
    "    \n",
    "    if len(data) == 0 : return \"无\"\n",
    "    \n",
    "    output = \"\"\n",
    "    FOLD_MAX = 3 # 超过多少个安科进行折叠\n",
    "    BRIEF_NUM = 20 # 简介字数\n",
    "    \n",
    "    if len(data)>FOLD_MAX : output += f\"[collapse={len(data)}个安科]\"\n",
    "    \n",
    "    output += \"[list]\\n\"\n",
    "    for index,row in data.iterrows():\n",
    "        \n",
    "        \n",
    "        title = str(row['title'])\n",
    "        \n",
    "        # 是否为本周新发布安科\n",
    "        recommend_tag = \"\"\n",
    "        if (datetime_last <= row['publish_time']) and (row['publish_time'] <= datetime_this):\n",
    "            recommend_tag += \"[color=green][b][新][/b][/color]\"\n",
    "        \n",
    "        if re.search(\"\\[创作活动-异界转生\\]\",title):\n",
    "            recommend_tag += \"[color=orangered][b][活动][/b][/color]\"\n",
    "        \n",
    "        if re.search(\"\\[恢复更新\\]\",title):\n",
    "            recommend_tag += \"[color=blue][b][复更][/b][/color]\"\n",
    "        \n",
    "        \n",
    "        # 标题处理\n",
    "        title = title.replace(\"[安科/安价]\",\"\")\n",
    "        title = title.replace(\"[安价/安科]\",\"\")\n",
    "        title = title.replace(\"[安科]\",\"\")\n",
    "        title = title.replace(\"[安价]\",\"\")\n",
    "        \n",
    "        # title = re.sub(r\"(\\[.*?\\])\",\"[color=silver]\\g<1>[/color]\",title)\n",
    "        # title = re.sub(r\"(\\(.*?\\)|（.*?）)\",\"[color=silver]\\g<1>[/color]\",title)\n",
    "        title = re.sub(r\"(\\(.*?\\)|（.*?）)\",\"\",title) # 删除所有括号\n",
    "        title = re.sub(r\"(\\[创作活动-异界转生\\])\",\"[b]\\g<1>[/b]\",title) # 将活动标签标粗\n",
    "        title = re.sub(r\"(\\[.*?\\])\",\"\",title) # 删除所有标签\n",
    "        \n",
    "        title = title.strip()\n",
    "        \n",
    "        if title == '': title = '[del]（此安科因标题全部由标签或者括号文本构成而被处理掉了）[/del]'\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 读取数据\n",
    "        # brief = get_brief(row['tid'],20)\n",
    "        \n",
    "        reply_time = f\"({(datetime_this-row['reply_time']).days}天前更新)\" if show_reply_time else \"\"\n",
    "        \n",
    "        output += f\"[*][{row[col_name]}]{recommend_tag}[url=https://ngabbs.com/read.php?tid={row['tid']}]{title}[/url]{reply_time}\\n\"\n",
    "    output += \"[/list]\"\n",
    "    \n",
    "    if len(data)>FOLD_MAX : output += \"[/collapse]\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_exceed_prompt(x:int):\n",
    "    return f\"[color=silver]已超过{num_lower_than_x(x)}/{thread_sum}=[b]{round(num_lower_than_x(x)/thread_sum*100,2)}%[/b]的安科[/color]\"\n",
    "\n",
    "def set_milestone(x:int,next_x:int):\n",
    "    this_milestones = filter_arrive_x_level(data_last,data_this,x)\n",
    "    next_milestones = filter_arrive_x_level(data_last,data_this,next_x)\n",
    "    this_milestones = diff(this_milestones,next_milestones) # 去除下一个里程碑里含有的帖子\n",
    "    \n",
    "    label = f\"{x}层\"\n",
    "    desc = \"\" #等级描述\n",
    "    \n",
    "    if x == 50: \n",
    "        label = \"[color=green][b]50层(入门级)[/b][/color]\"\n",
    "        desc = \"\"\n",
    "    if x == 500: \n",
    "        label = \"[color=blue][b]500层(殿堂级)[/b][/color]\"\n",
    "        desc = \"\"\n",
    "    if x == 5000: \n",
    "        label = \"[color=purple][b]5000层(传说级)[/b][/color]\"\n",
    "        desc = \"\"\n",
    "    if x == 50000: \n",
    "        label = \"[color=red][b]50000层(神话级)[/b][/color]\"\n",
    "        desc = \"\"\n",
    "    \n",
    "    return f\"\"\"[align=center][size=150%]{label}[/size]\n",
    "{get_exceed_prompt(x)}\n",
    "{desc}[/align]\n",
    "[quote]{data_to_bbcode(this_milestones)}[/quote]\n",
    "\"\"\"\n",
    "\n",
    "def set_milestones(milestone_list:list):\n",
    "    output = \"\"\n",
    "    for i in range(len(milestone_list)):\n",
    "        x = milestone_list[i]\n",
    "        next_x = milestone_list[i+1] if i+1 < len(milestone_list) else milestone_list[i]\n",
    "        output += set_milestone(x,next_x)\n",
    "    return output\n",
    "\n",
    "output = f\"\"\"[align=center][size=200%][b]周报基础内容[/b][/size][/align]\n",
    "[quote][collapse=相关说明][list]\n",
    "[*]下文的“本周”所指代的时间段为：{datetime_last} ~ {datetime_this}\n",
    "[*]没有[安价/安科]、[安科/安价]、[安科]、[安价]等tag的帖子，会筛掉，可以在周报楼后面自行补充（然后自行改好tag不然下次还是一样）。\n",
    "[*]在数据采集时间点附近进入审核的帖子，有可能被遗漏，可以在周报楼后面自行补充。\n",
    "[*]方括号内的数字代表采集数据时帖子的楼层数。\n",
    "[*]带有[color=green][b][新][/b][/color]标签的安科是在本周新发布的安科。\n",
    "[*]带有[color=orangered][b][活动][/b][/color]标签的安科是参与活动的安科。可以是自行举办的活动，跟我说就可以加上活动标签。\n",
    "[*]带有[color=blue][b][复更][/b][/color]标签的安科是曾经断更但现在恢复更新的安科。\n",
    "[/list]\n",
    "\n",
    "“本周完结”的判断标准：上周未在完结区，而本周在完结区内，或是主动告诉我。\n",
    "\n",
    "筛选“本周达到里程碑的安科”使用的算法概述：\n",
    "1. 列表A为本周的数据中大于等于x层的帖子，列表B为上周的数据中大于等于x层的帖子\n",
    "2. 去除在本周之前已经达到x层的帖子，也就是获取二者差集，即 C = A - B。\n",
    "3. 如果某个帖子出现在C中，但是不存在于B中，说明这个帖子在收集上周数据时进入了审核或者是这周新发布，如果是前者，则从结果中去除，避免出现“在本周之前达成x层的帖子进入本周达成列表”的情况\n",
    "4. 去除“地下城”和“图书馆”分区的帖子\n",
    "5. 按照楼层升序排列\n",
    "[/collapse][/quote]\n",
    "\"\"\"\n",
    "# 本周活跃数据\n",
    "output += f\"\"\"[align=center][size=150%][b]本周版面活跃数据[/b][/size][/align]\n",
    "[quote]本周有[b]{len(active_data)}[/b]篇旧安科处于活跃状态，在这周总共增长了{int(active_data.sum())}层，平均每一篇增长{round(active_data.mean(),2)}层。其中楼层增长最多的安科增长了{int(active_data.max())}层，楼层增长最少的安科增长了{int(active_data.min())}层。\n",
    "\n",
    "本周新增{len(new_threads)}篇安科，在这周总共增长了{int(new_threads['level'].sum())}层，平均每一篇增长{round(new_threads['level'].mean(),2)}层。其中楼层增长最多的安科增长了{int(new_threads['level'].max())}层，楼层增长最少的安科增长了{int(new_threads['level'].min())}层。[/quote]\n",
    "\"\"\"\n",
    "\n",
    "# 复更安科\n",
    "output += f\"\"\"[align=center][size=150%][b]复更宣传栏[/b][/size][/align]\n",
    "[quote]众所周知，写安科断更是非常常见的事情，甚至你只要达到50层还没有断更，就足以超过一半的安科作者。但也有一些安科作者在打败了现实恶魔之后，回来恢复更新，却因为断更太久而无人问津。\n",
    "\n",
    "本栏目就是为了帮助这些恢复更新的安科作者找回以前的读者，进行一定程度的宣传。规则如下，因为是试运行，有可能会改动规则：\n",
    "\n",
    "1.将会列出所有在标题标记了[b][color=blue][恢复更新][/color][/b]的tag[color=red]（注意不是[b][复更][/b]，下面标注的[b][复更][/b]是为了节约篇幅以更多展示你标题的）[/color]，且最后回复时间在30天以内的安科\n",
    "2.精力有限，一般不会主动检查，但请不要滥用此tag。一般来说，挂了一个月已恢复稳定更新后，或者再次断更等情况，请自觉撤下该tag[/quote]\n",
    "\n",
    "[quote]{data_to_bbcode(get_revive_threads(data_this),show_reply_time=True)}[/quote]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 本周完结的内容\n",
    "output += f\"\"\"[align=center][size=150%][b]本周完结的安科[/b][/size][/align]\n",
    "[quote]{data_to_bbcode(finished_threads)}[/quote]\n",
    "\"\"\"\n",
    "\n",
    "# 本周达到里程碑的安科\n",
    "output += f\"\"\"[align=center][size=150%][b]本周达到里程碑的安科[/b][/size]\n",
    "[/align]\n",
    "{set_milestones([25,50,100,250,500,1000,2500,5000,10000,25000,50000])}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制结果\n",
    "pyperclip.copy(output)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_data = active_data.sort_values(ascending=False)\n",
    "\n",
    "# active_data += new_threads['level']\n",
    "\n",
    "data_this['incLevel'] = active_data.astype(int)\n",
    "\n",
    "data_this = data_this.fillna(0)\n",
    "\n",
    "data_this = data_this.sort_values(by='incLevel',ascending=False)\n",
    "\n",
    "hot_thread = data_this.head(10)\n",
    "\n",
    "print(data_to_bbcode(hot_thread,'incLevel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ca84ab3dd459228c068eecb63c01db592bf79b47e15435caf3ef74bc85045e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
